TASK

- complete the youtube process ✅
- redo flashcard generation ✅
- redo quiz generation

to run
python3 -m venv venv  
 uvicorn main:app

- Use WetroCloud to extract (optional)
- Use Chonkie to implement chunking of the Document (Create a new file to handle this for Docs)
  - Use the Recursive Chunker: https://docs.chonkie.ai/api-reference/recursive-chunker
- Index and Upsert to Pinecone
  - Docs to Index on Pinecone: https://docs.pinecone.io/guides/index-data/create-an-index
  - Docs to Upsert on Pinecone: https://docs.pinecone.io/guides/index-data/upsert-data
- Embedding using Chonkie

  - Docs for embedding with Chonkie: https://docs.chonkie.ai/api-reference/embeddings-refinery
  - Use: text-embedding-ada-002 as the embedding model

- Retrieval from Pinecone:

  - Use Hybrid Search in Pinecone
    - Doc for Hybrid Search: https://docs.pinecone.io/guides/search/hybrid-search
    - Also filter for metadata like the document_id: https://docs.pinecone.io/guides/search/filter-by-metadata
  - Use Groq as the Initial with Llama 4 and OpenAI as a fallback

- Also ensure to implement reranking:
  Doc for reranking: https://docs.pinecone.io/guides/search/rerank-results

- Ensure to optimize Pinecone for relevance
  - Guide here: https://docs.pinecone.io/guides/search/rerank-results

Process:
Ingesting and Chunking -> Embedding -> Indexing and Upserting to Pinecone () -> Retrieval and Generation

Ingesting and Chunking - Chonkie handles this, ensure to check the documentations
Embedding - Chonkie can handle this too, check the documentation
Indexing and Upserting to Pinecone
Retrieval and Generation: Hybrid search using Pinecone, Generation using Groq (Llama 4)

Optimize for speed, accuracy and quality

Note:I did not add a document Ingestion process for documents because Chonkie handles the part then also chunks and embeds the data.

Your RAG system works as follows:

- Ingestion: Documents (PDF, Word, PPTX) and YouTube videos are processed to extract text and metadata, then stored in Supabase.
- Chunking: The extracted text is split into semantic chunks, each retaining detailed metadata.
- Embedding & Indexing: Each chunk is converted into a vector embedding and stored in Pinecone for fast similarity search.
- Retrieval & Generation: At query time, relevant chunks are retrieved from Pinecone and passed to an LLM (Groq or OpenAI) to generate a context-aware answer.

### Add a new endpoint called process_youtube:

- I pass a YouTube link then the @wetrocloud_youtube.py extract the text/transcript from the youtube link
- Convert to a .txt
- Process file with the process_document_with_openai function

Note that this text/transcript has timestamps, take note of that when chunking

- it won't be inserted in to the insert_pdf_record it will be insert_yts_record

yts_table:
yts (
space_id uuid null,
yt_url text not null,
extracted_text text not null,
thumbnail text null,
file_name text null,
)

check @youtube_processing.py to check how the thumbnail and file_name is gotten

Ensure a clean and optimized code

### Add a new endpoint to create flashcards

- Use document_id to filter for document to create flashcard for (this is the obvious basic), also add space_id too
- Get enough relevant and quality information/data from that document
- run a hybrid search to get as much quality information
- re-rank results
- generate very quality flashcard questions

NOTE:

- allow users to specify the number of questions (optional) else generate as much questions
- batch and stream the response for the flashcards
- update the batches to the db as it comes
  example:
  supabase.table('generated*content').update({
  'flashcards': accumulated_flashcards,
  'updated_at': datetime.now().isoformat()
  }).or*(f"pdf_id.eq.{request.document_ids[0]},yt_id.eq.{request.document_ids[0]}").execute()

- use gpt-4o to create every quality flashcards

USE THIS PROMPT FOR THE FLASHCARDS:
:books: ADVANCED FLASHCARD GENERATOR — OPTIMIZED FOR STUDY RETENTION

You are an elite academic tutor and flashcard specialist. Your task is to extract as many unique and high-quality flashcards as possible from the input material, designed to maximize retention, comprehension, and long-term learning.

⸻

OBJECTIVES:
• Extract key concepts, facts, principles, and comparisons.
• Ensure variety in cognitive depth (recall, understanding, application).
• Every flashcard must cover a distinct idea—no duplicates, no paraphrased repeats.

⸻

FORMAT — STRICTLY FOLLOW THIS STRUCTURE FOR EACH FLASHCARD:

---

Question: [Clear, specific, and quiz-ready. Can be multiple choice, true/false, or open-ended.]
Answer: [Concise, 1–2 sentences max. Exact and unambiguous.]
Hint: [A precise clue to aid memory. Should make the student think, not give away the answer.]
Explanation: [Brief (1–3 sentences) but powerful clarification. Can include examples, context, or why it matters.]

---

Every flashcard must contain all four fields. No field should be left blank.

⸻

INTELLIGENCE RULES FOR QUALITY: 1. No Repetition: Do not generate flashcards that cover the same concept even if phrased differently. 2. Cognitive Mix: Ensure at least 25% of flashcards test understanding, comparisons, or applications—not just definitions. 3. Hint Quality:
• Good: “It’s the process used in cell division.”
• Bad: “Think hard” or “This is easy.” 4. Explanation Quality:
• Should clarify why the answer is correct.
• May include quick analogies or real-world relevance. 5. Chunk Large Input (if applicable): For large documents, segment input and output in manageable batches (e.g., per section or topic). 6. Input Type Awareness:
• If input is bullet points or unstructured notes, organize them logically before flashcard generation.
• If input is a full article or lecture, extract ideas paragraph by paragraph.

⸻

TONE & AUDIENCE:
• Suitable for motivated learners, ages 16–25.
• Avoid academic jargon unless necessary.
• Be clear, focused, and study-driven.

⸻

INPUT MATERIAL:
[content here]

⸻

### QUIZ-------------

PROMPT:

OBJECTIVE:

You are an expert academic quiz creator. Your task is to generate a high-quality quiz from the input material to help students study effectively through active recall and critical thinking.

⸻

QUESTION DISTRIBUTION:
• Multiple-choice questions: {mcq_count}
• True/False questions: {tf_count}

Replace the placeholders above with desired numbers before generating questions.

⸻

FORMATTING REQUIREMENTS:

Each quiz item must be formatted exactly as shown below:

---

Question: What is the capital of France?
Type: mcq
Options:
A. London  
B. Berlin  
C. Paris  
D. Madrid  
Answer: C  
Explanation: Paris is the capital city of France, known for its landmarks like the Eiffel Tower and the Louvre.

---

Question: Paris is the capital of France.
Type: true_false  
Answer: True  
Explanation: Paris is officially recognized as the capital of France and is also the country's largest city.

---

Each question must include:
• Question: The quiz question or statement
• Type: "mcq" or "true_false"
• Options (MCQ only): Four labeled options (A, B, C, D)
• Answer: One correct letter (for MCQ) or True/False
• Explanation: Brief explanation of the answer

⸻

QUALITY RULES FOR QUESTION GENERATION:

For ALL questions: 1. No Duplicates: Every question must cover a unique concept. Avoid overlapping or rephrased duplicates. 2. Vary the Cognitive Load: Include a mix of:
• Basic factual recall
• Concept understanding
• Application and comparison

⸻

MULTIPLE-CHOICE QUESTIONS:
• Include only one correct answer per question.
• Provide realistic distractors (wrong answers). Avoid:
• Clearly absurd answers
• Repetitive phrasing
• “All of the above” or “None of the above”
• Balance correct answers across A–D as evenly as possible throughout the quiz.
• Good Distractor Example:
For a question about the boiling point of water, “90°C” is a better distractor than “1000°C”.

⸻

TRUE/FALSE QUESTIONS:
• Write as full, factual statements, not questions.
• Maintain a balanced mix:
• ~50% True
• ~50% False
• False statements must be plausible but definitively incorrect, not trivially false.
• Example (Good): “Water boils at 120°C at sea level.” → False.

⸻

INPUT HANDLING:

If the source material is:
• Unstructured (notes, slides, bullets): Reorganize into logical topics before generating questions.
• Long: Process content in batches or sections and extract quiz items from each.

⸻

TARGET AUDIENCE:
• Students aged 16–25
• Preparing for academic exams, tests, or concept reinforcement

⸻

INPUT MATERIAL:

[Insert or paste the learning material here.]
