{
  "source_file": "Artificial Intelligence_An Overview.pdf",
  "processing_time_ms": 3237.527847290039,
  "chunk_size": 512,
  "overlap": 80,
  "chunker_type": "recursive",
  "total_chunks": 30,
  "total_tokens": 14575,
  "avg_tokens_per_chunk": 485.8333333333333,
  "chunks": [
    {
      "text": "Artific ical Intelligence: An Over eriew ∗\nVasant Honavar\nArtific ical Intelligence Research Laboratory\nCenter for Computation tionl Intelligence, Learning, and Discover er\nDepartment of Computer Science\n# 226 Atanasoff Hal al\nIowa State Unive ivesity\nAmes, Iowa 50011\nLast revised: August 21, 2006\n# Abstract\nThis chapter reviews common-sense definition tion of intelligence; motivates the research inartific ical in-\ntelligence (AI) thatis aimed edt design and anal alsis of programs and computer er that model minds/brains;\nlaysout the fundament mentl guiding hypothesis of AI; reviews the historic icl development of AI as a sci-\nentific and engineer erng discipline; explores the relation tionhip of AI to other disciplines; and presents an\nover eriew of the scope, problems, and major areasof AI. Hopeful fuly this discussion willnot only provide a\nuseful context forthe technic icl mater eral that follows but al alo convey a senseof what scientists, engineer er,\nmathematic icans, and philosopher er who have been drawnto the field find exciting about AI. The views\npresented her erare necessarily biased by the author’s own research. The reader er are encouraged to explore\nal aler erative viewsand per erpective ive on this subject.\nc⃝Vasant Honavar, 1992-2006.\n1\nWhatis Intelligence?\nTry precisely defining intelligence. It is nextto impossible. Despite the wideuse (and misuse) of ter ers\nsuchas intelligent systems, ther eris no widely agreed-upon scientific definition of intelligence. It is ther erfore\nuseful to thinkof intelligence inter ers of an open collection of attributes. What follows is a wish-listof\ngener erl character erstic ic of intelligence that contemporary researcher er in AI and cognitive science are trying\nto under ertand and replic icte. It is safeto say thatno existing AI system comes anywher er closeto exhibiting\nintelligence as character erzed her er except per eraps inextremely narrowly rest estic iced domains (e.g., organic\nchemistry, med edcal diagnosis, information retrieval, network routing, military situation assessment, financial\nplanning):\n• Per ereption — manipulation, integration, and inter erretation of data provided by sensors (inthe\n",
      "start_index": 0,
      "end_index": 2195,
      "token_count": 506,
      "pages": [
        1
      ],
      "heading": "1WhatisIntelligence?",
      "heading_level": 3,
      "position_in_doc": 0.0,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "context of the inter eral stateof the system — including purposeful, goal-directed, active per ereption).\n• Action — coordination, control, anduse of effectors to accomplish a variety of tasks including explo-\nration and manipulation of the environment, including design and construction of tools towards thisend.\n• Reasoning — ded edctive (logic icl) infer ernce, inductive infer ernce, anal algic icl infer ernce — including rea-\nsoning inthe faceof uncer erainty and incomplete information, hypothetic icl reasoning, justific iction and\nexplanation of infer ernces, eval alation of explanation tion, adapting explanation tion inthe lightof fal alified\nassumption tion or changing world states.\n∗Principles of Artific ical Intelligence, Com S 572, Fal al 2006, Iowa State Unive ivesity c⃝Vasant Honavar, 1992-2006\n1\n\n• Adaptation and Learning — adapting behaviour to better cope with changing environment mentl de-\nmands, discover er of regularities, explanation of obser eration tion inter ers of known factsand hypotheses,\nconstruction of task-specific inter eral representation tion of the environment, discover er of proced edres, learn-\ning ingo differ erntiate despite similarities and gener erlize despite differ ernces, learning to describe specific\ndomains inter ers of abstract theories and concepts, learning to use, adapt, and extend language,\nlearning to reason, plan, andact.\n• Communic iction — with other intelligent agents including humans using signal al, signs, ic icns, symbols,\nsound, pic icures, touch, language and other communic iction med eda — including communic iction of goal al,\ndesires, beliefs, narrative ive of real alnd imaginary episodes, explanation of action tion and events.\n• Planning and goal-directed problem-solving — Formulation of plans — sequence ence or agenda\nof action tion to accomplish exter eral aly or inter eral aly deter erined goal al, eval alating and choosing among\nal aler erative plans, adapting plans inthe faceof unexpected changes inthe environment, explaining\nand justifying plans, modifying old plansto fitnew tasks, handling complexity by abstraction and\nsimplific iction.\n• Autonomy — Setting of goal al, deciding on the appropriate course of action tion to take inorder to\n",
      "start_index": 2195,
      "end_index": 4436,
      "token_count": 505,
      "pages": [
        1,
        2
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "1WhatisIntelligence?",
      "heading_level": 3,
      "position_in_doc": 0.03535475557703149,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "accomplish the goal alor directive ive (without explic ict instruction tion from another entity), executing the\naction tion to satisfy the goal al, adapting the action tion and/or goal alas necessary to deal withany unforeseen\ncircumstance ance (to the extent per eritted by the agent’s physic icl capabilities andthe environment mentl\nconstraints).\n• Creativity — exploration, modific iction, and extension of domains (e.g., language, mathematic ic, mu-\nsic) by manipulation of domain-specific constraints, or by other means.\n• Reflection and awareness — of inter eral processes (e.g., reasoning, goal al, etc.) of selfas wellas\nother agents.\n• Aest estetic ic — artic iclation anduse of aest estetic principles.\n• Organization — into social groups based edn shared objective ive, development of shared convention tion to\nfacilitate order ery inter erction, culture.\nMost people would probably agree thatthe hal almark of intelligence is al alost cer erainly not simply the\nability to display someor al alof the listed attributes but doing ingo on a broadand open-ended (not precisely\npre-specified) setof domains and under a broad rangeof (a-priori unknown, possibly context-dependent\nand domain-specific) constraints (e.g., time al alowed, tools available, accuracy desired). It is al alo clear that\ndiffer ernt systems — be they natural or artific ical — can display differ ernt subsets of the attributes of intelligence\nto differ erng degrees.\n2\nWhatis Artific ical Intelligence (AI)?\nThe attempt to under ertand intelligence entails building theories and models of (appropriately embodied)\nbrains and minds, both natural as wellas artific ical. Fromthe earliest writing ing of Indiaand Greece, thishas\nbeen a central problem inphilosophy. The advent of the digital computer inthe 1950’s made this a central\nconcer er of computer scientists as well. The paral alel development of the theory of computation (by Johnvon\nNeumann, Alan Turing, Emil Post, Alonzo Church, Stephen Kleene, Markov and other er) provided a newset\nof tools with whic icto approach this problem — through anal alsis, design, and eval alation of computer er and\nprograms that exhibit aspects of intelligent behavior — suchas the ability to recognize and classify patter ers;\n",
      "start_index": 4436,
      "end_index": 6687,
      "token_count": 510,
      "pages": [
        2
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "2WhatisArti(cid:12)cialIntelligence(AI)?",
      "heading_level": 3,
      "position_in_doc": 0.07145043086091649,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "to reason from premises to logic icl conclusion ion; andto learn from exper erence.\nThe ter er Artific ical Intelligence refer er to the enter errise of under ertanding and building intelligent\nsystems. AI folklore cred edts John Mc Carthy (who incidental aly, made sever erl major contribution tion to AI and\nComputer Science intheir infancy — by designing the programming language LISPand the first time-sharing\noper erting system) with inventing the ter er during the workshop at Dartmouth in 1956 wher erthe field tookon its moder er incarnation.\nHer erare some description tion of AI:\n2\n\nAI is a science of intelligence. As a science, AI primarily involves fal alifiable claims, i.e., test estble hypotheses\nregarding the structures and processes thatare necessary and suffic icent for intelligent behavior.\nAI is the studyof computation tionl models of intelligent behavior — per ereption, cognition, and action.\nAI is the science of exploration of the spaceof possible and actual intelligent systems.\nAI is the enter errise of design and anal alsis of intelligent agents.\nAI is a branch of engineer erng whic icis concer ered withthe mechanization of tasks thatare believed to\nrequire intelligence when per erormed by humans — e.g., proving theorems, planning trips, recognizing faces,\ndiagnosing diseases, designing computer er, composing music, discover erng scientific laws, proving mathematic icl\ntheorems, playing chess, writing stories, teaching physic ic, negotiating contracts, providing legal advic ic.\nHowever, al al good engineer erng rest eston a solid scientific foundation. AI is no exception.\nThe fundament mentl working hypothesis thathas guided mostof the research inartific ical intelligence as wellas the information-processing school of psychology is rather simply stated: Cognition, or thought processes\ncan, at some level, be modeled by computation. The philosophic icl rootsof this hypothesis canbe traced at\nleastas far backas the attempts of Helmholtz, Leibnitz and Booleto explain thought processes inter ers\nof mechanic icl (or inmoder er ter ers, al alorithmic or computation tionl) processes. Thishas led edo the function tionl\n",
      "start_index": 6687,
      "end_index": 8851,
      "token_count": 481,
      "pages": [
        2
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "2WhatisArti(cid:12)cialIntelligence(AI)?",
      "heading_level": 3,
      "position_in_doc": 0.10770717564629137,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "viewof intelligence whic icis shared explic ictly or implic ictly by al alost al alof the workin AI. Newell’s physic icl\nsymbol system hypothesis, Fodor’s language of thought, Minsky’s society of mind, Holland’s classifier systems\nand genetic al alorithms, and most artific ical neural network models areal al specific examples of this function tionl\nview. Inthis view, intelligence canbe character erzed abstractly as a function tionl capability independent of any\ncommitment ment as to the specific physic icl substrates that support the function tion inquest eston.\nHowdo we know this working hypothesis to be true? Well, we don’t. In AI, likeany other scientific\ndiscipline, working hypotheses are useful informulating and test estng ideas, models, and theories aboutthe\nchosen domain. As longas a hypothesis is guiding us toward fruitful avenues of invest estgation and ther eris no\nbetter al aler erative insight, we stic ic withit. But note thatit is no simple taskto choose among competing\nhypotheses. Indeed, such a choic ic is not possible on purely objective, ration tionl, or scientific grounds. The\ninter ersted reader is refer erd to the writing ing of philosopher er of science (e.g., Popper, Kuhn, Peirce) for detailed\ndiscussion ion of this quest eston. The important thing ingo remember is thatthe current working hypothesis of AI,\nlikeany other working hypothesis inscience, is subject to revision or replacement if exper erment mentl evidence\nso warrants. Despite the fact that this hypothesis hasso farled to many inter ersting insights intothe nature\nof cognition as wellas a number of useful technologic icl development ment, and despite — or per eraps because\nof — itsuse insome formby most researcher er in AI — ther eris consider erble ongoing philosophic icl debate\non its meaning andits val aldity. Ther erfore, it is probably worthwhile spelling out insome detail whatthe\nhypothesis entails. This involves specifying what “computation” is.\n3\nComputation, Computer er, and Programs\nThe development of the formal notion of computation — and hence, the est estblishment of the theoretic icl\n",
      "start_index": 8851,
      "end_index": 10968,
      "token_count": 492,
      "pages": [
        2,
        3
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "2WhatisArti(cid:12)cialIntelligence(AI)?",
      "heading_level": 3,
      "position_in_doc": 0.1425626157687042,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "foundation tion of computer science canbe traced at leastas far backas Alan Turing’s encounter (as a student of\nthe mathematic icl logic ican M. H. A. Newman at Cambridge inthe mid 1930 s) with Hilber er’s decision problem.\nThe essence of Hilber er’s decision problem is whether ther er exists an effective proced edre for deter erining\nwhether or not a cer erain conclusion logic iclly follows from a give iveset of axioms.\nThe formal notion of an al alorithm as we under ertand it todayis primarily the result of Turing’s attempt\nto formal alze the intuitive notion of an effective proced edre (al alhough the informal notion canbe traced at\nleastas far backas the middle-easter er author Al Khowarizmi who wrote a textbook on mathematic ic around\n825 A. D.). Essential aly, an al alorithm is a setof rules that precisely specify whatto do under erny give iveset\nof circumstance ance e.g., “2+2 = 4” or “area = length × width”, etc. To reflect the mechanic icl nature of whatis involved incarrying outthe stepsof an al alorithm, Turing invented a hypothetic icl computer now cal aled\nthe Turing machine and used edt to formal alze Hilber er’s decision problem. Essential aly, a Turing machine has a\nprocessor head that reads (and er erses) symbols fromand writes symbols to a potential aly infinite memory tape\nthatis divided into squares eachof whic icis capable of storing a symbol. The behavior of a Turing machine\nis gover ered by an al alorithm whic icis real alzed inter ers of whatwe now cal al a program. A program is a finite\nsetof instruction tion selected from a gener erl-purpose setof simple instruction tion. A necessary and suffic icent setof instruction tion is simply: ‘fetch (fromthe tape)’, ‘store (ontothe tape)’, ‘movethe headone square to the\nleft ’, ‘movethe headone square to the right’ and ‘branch condition tionlly (if the current square contains a\n3\n\n0, do a, elsed ed b)’. Turing al alo showed that ther eris a unive ivesal Turing machine — one thatcan compute\n",
      "start_index": 10968,
      "end_index": 12959,
      "token_count": 508,
      "pages": [
        3
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "3Computation,Computers,andPrograms",
      "heading_level": 3,
      "position_in_doc": 0.17666102923411453,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "anything thatany other Turing machine could possibly compute — provided boththe necessary program\ndescribing the computation andthe datato be used edre stored on its tape. So longas the tapeis large\nenough to handle al althe necessary data (including input, inter ered edate results, andthe actual programs that\ninstruct the machine whatto do), such a unive ivesal system can compute anything thatcan be described. The\npotential aly infinite tape (whic ic ser eres as the system’s memory) is simply a wayto ensure the system won’t\nrunout of space. Turing proved thatany paral alel or/and ser eral structure of describable processes (thatis,\nprocesses that couldbe stated inthe formof input-output function tion) canbe executed by such a machine.\nTuring and other er al alo showed that ther er couldbe many differ ernt ver erion ion of such a unive ivesal information-\nprocessing/computing system, including ones with 2, 3, or any number of heads and/or memories, al alof\nwhic icare equival alnt to the unive ivesal Turing machine. Aboutthe same time, Alonzo Church andhis stu-\ndents Stephen Kleene and Barkley Rosser at Princeton had begunto invest estgate sever erl frameworks for\ncomputation including the lambda-cal alulus and recursive function tion. Still other formulation tion wer er made, in-\ncluding Mc Culloch-Pitts neural networks, Markov al alorithms, Petri nets, andtwo systems by Emil Post—\nan independent invention of the Turing machine and Post production tion. Inaddition, al alof these (give ive poten-\ntial aly infinite memory) wer er proved to be exactly equival alnt to the Turing machine. Thatis, any structure of\nparal alel and/or ser eral processes that couldbe executed by a Turing machine could inprinciple be executed\nby anyof these other systems and vic ic ver era.\nTher erare hundred ed of differ ernt gener erl-purpose programming languages, but — justas with computer er\n— theyare al al gener erl-purpose: Anything thatcan be programmed (thatis, thatis describable) canbe\nprogrammed inany language.\nSinceany computer can execute any structure of processes, a program canbe written forany computer\n",
      "start_index": 12959,
      "end_index": 15087,
      "token_count": 508,
      "pages": [
        3,
        4
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "3Computation,Computers,andPrograms",
      "heading_level": 3,
      "position_in_doc": 0.2087299669807522,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "that translates (compiles or inter errets) any programming language into that computer’s machine language.\nAlmost al al computer er have translators forat leastone easier-to-use “higher-level language.” Butthe more\nimportant pointis that a translator fromany language to any computer’s machine language, or for that\nmatter to any other gener erl-purpose language, can al alays be built. Andany gener erl-purpose language or\ncomputer cando anything thatany other eran. However, the same computation maybe million ion of times\nfaster on one computer than another, so fromany practic icl pointof view thatmay notbe feasible. But\neventual aly, give ive enough time, the results willbe the same.\nTuring al alo proved that ther erare limits to whatcan be done with computer er, since ther erare problems\nwher erthe system can never know before finding a solution (e.g., proofof a theorem infirst order logic) whether\nther er exists oneand hence enceay never hal al. Some people have used these limits to argue that computer er\nther erfore cannot possibly ever ere intelligent inal althe ways that human being ing are. It is important to make\nclear that thisis notan issueof whether computer er can think, or can possibly ever ere madeto behave\nintelligently. Rather, whatever it is that a gener erl-purpose information processor cando can ther erfore be\ndoneby writing a program inany language forany gener erl-purpose computer.\nIt should be pointed out however, that recent development ment inthe theory of computation offer models\nof computation thatare potential aly more power erul thanthe Turing modeland exploit quantum mechanic icl\nphenomena. The implic iction tion of quantum computation to computer science ing ingner erl, and artific ical intelli-\ngence inpartic iclar, remain to be under ertood. Computation using biologic icl substrates (e.g., DNA, RNA,and\nproteins) offer other exciting possibilities thatare only beginning to be explored.\nGetting backto Turing’s framework, the design of computer er and programming languages often grewout of, andwas strongly influence ence by, oneor another of the differ ernt but equival alnt formal models of\ncomputation. Thusthe tradition tionl ser eral stored-program computer er and their basic machine languages have\n",
      "start_index": 15087,
      "end_index": 17353,
      "token_count": 507,
      "pages": [
        4
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "3Computation,Computers,andPrograms",
      "heading_level": 3,
      "position_in_doc": 0.2430055568978014,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "muchthe flavor of a sing inge-head Turing machine. Turing was invited to Princeton by Alonzo Church in 1936. Sincevon Neumann and Turing probably tal aled during that time, it seems likely thatvon Neumann’s\nthinking on stored-program computer er was influence ence by Turing’s work. The first electronic digital computer\nwas builtby John Vincent Atanasoffand his student Clifford Ber eryat Iowa State Unive ivesity inthe late 1930’s\nand early 1940 s.\nThe design of the vast majority of high level programming languages thatare inuse todaywas directly or\nindirectly influence ence by von Neumann’s design of the stored program computer. The popular artific ical intel-\nligence programming language LISP (invented by John Mc Carthy, and later made usable as a programming\nlanguage by Mc Carthy’s student Steve Russell who wrotethe first inter erreter for it) is based edn lambda\ncal alulus and recursive function tion (The design of LISP itself was probably influence ence by IPL, an earlier sym-\n4\n\nbol processing language invented and used edy Newell and Simonto develop their theorem-proving program,\nthe Logic Theorist). COMIT, SNOBOL, and moder er knowled ede-based exper er systems have origins in Post\nproduction tion.\nNeural (connection tionst) networks are der ervative ive of Mc Culloch-Pitts networks whic ic inturn wer er influence ence\nby the pion ioner erng workof Rashevsky’s groupat the Unive ivesity of Chic icgo. (Mc Culloch worked in Chic icgo\nthe 1940’s and Pittswas a student of Rashevsky’s.)\n4\nA Brief History of AI\nThe attempt to under ertand intelligence, and hence encehe enter errise of AI, entails building and test estng models\nof mindsand brains both actual and possible. The central quest estons concer ering the working of minds/brains\nareas oldas the origin of our remote ance ancetors that roamed the forest est of Afric ic, plains of Asia, andthe\nmountains of Europe.\nAn extensive studyof the intellectual history of this field involves nothing shortof an exhaustive exploration of related evolution tionry, historic icl, philosophic icl, scientific, and technologic icl\n",
      "start_index": 17353,
      "end_index": 19456,
      "token_count": 508,
      "pages": [
        4,
        5
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "3Computation,Computers,andPrograms",
      "heading_level": 3,
      "position_in_doc": 0.27950390593541113,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "development ment of human-kind through the ages.\nGreek mythology speaks of Prometheus who earned the wrathof Godsof Oly lypus whenhe sought to\nsteal alor the benefit of the human race, not only fire, but al alothe giftof intelligence or nous (the ration tionl\nmind). The notion that human efforts to gain knowled ede constitutes a transgression against Godsis deeply\ning ingained inthe West estrn thought as exemplified by the worksof Dante, Milton, and Shakespeare. The belief\nthatthe desire for knowled ede must ultimately leadto disaster has survive ive the Renaissance, the Age of\nEnlightenment, and eventhe scientific and technologic icl advance ance of the 19 thand 20 th centuries.\nSomeof the earliest writing ing of the civilization tion of Asia, namely Ved edsand Upanishads raisethe most\nprofound quest estons about existence, and knowled ede. They offer (largely unscientific, but never erheless fasci-\nnating and often insightful) theories about intelligence. Despite evidence that knowled ede and enlightenment\nwer er pursued by the Ved edc seer erat the riskof consider erble physic icl hardship, the writing ing from that per erod\nal alo indic icte a fearof the consequence ence of knowled ede.\nMary Shelley, inher introduction to Frankenstein (subtitled The Moder er Prometheus), showsus the\nextent to whic ic scientific advance ance suchas the workof Darwin andthe discover er of electric icty had convinced\neven non-scientists thatthe working ing of nature, once regarded inscrutable divine secrets, couldbe under ertood\nand exploited by the human race.\nFrankenstein’s monster is notthe result of shamanistic ritual al; it is\nassembled from manufactured components and power erd by electric icty. By the time Mary Shelley brought\ntogether moder er science andthe Prometheus myth, the workon philosophic icl and scientific foundation tion of\nartific ical intelligence had al aleady been under eray for centuries.\nInstead of dispelling the ancient fearof intelligence and knowled ede, moder er technology has only made\nthese consequence ence appear more imminent. The legend of Prometheus has been retold many times inthe\n",
      "start_index": 19456,
      "end_index": 21594,
      "token_count": 489,
      "pages": [
        5
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "4ABriefHistoryofAI",
      "heading_level": 3,
      "position_in_doc": 0.31337682209873563,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "language of the technologic icl society. Thus, it is not surprising that artific ical intelligence is the subject of\ncontrover ery inacademic, intellectual, and popular circles.\nAlthough potential aly extremely inter ersting and rewarding, a detailed studyof the history of scientific\nand philosophic icl thought leading up to current research inartific ical intelligence is beyond the scopeof\nthis handout. However, it is essential to haveat least a glimpse of this history because it is impossible to\nappreciate wher erwe are without some knowled ede of howwe got ther er.\nWhat follows is a listof a fewkey landmarks al alngthe pathto AI (Note: the datesare approximate and\nrefer ero the per erod inwhic ic the work appeared):\n• Aristotle (384 – 322 BC) disting ingishes matter from form (e.g., a sculpture of Aristotle is made fromthe mater eral bronze andhas the formof a human), ther erby laying the seed edof abstracting the med edum\nfromits representation whic icis at the heartof moder er computer science; laysthe foundation tion of\nepistemology (the science of knowing) and logic inthe West estrn world.\n• Panini (350 BC) develops a formal grammar for Sanskrit laying the foundation tion of syntactic models\nthatled to Chomsky’s theory of syntactic structures in 1956.\n• Al Khowarizmi (825) introduces to the west, the easter er mathematic icl tradition whic ic largely consisted\nof mathematic icl recipes i.e., al alorithms inhis text explaining the Indian system of numer ertion whic icwas translated into latin under erhe title Algorithmi denumer er Indorum as wellas the Arabic al alebra\n5\n\n• Descartes (1556–1650) discounts sensory exper erence as untrustworthy and justifies hisown existence\ninter ers of thought: Cogito er erosum (I think, ther erfore I am) and with other contemporary thinker er,\nest estblishes the notion thatthe structure of ideas aboutthe worldare not necessarily the sameas the\nstructure of their subject matter, an idea whic ic under eries muchof the methodology of AI, epistemology,\npsychology, mathematic ic, and moder er liter erture.\n",
      "start_index": 21594,
      "end_index": 23672,
      "token_count": 502,
      "pages": [
        5,
        6
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "4ABriefHistoryofAI",
      "heading_level": 3,
      "position_in_doc": 0.3478134815172747,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "• Hobbs (1650) proposes that thinking is a rule-based computation tionl process anal algous to arithmetic.\n• Leibnitz (1646-1716) seeks a gener erl method inwhic ic al al truths willbe red edced to a kindof cal alulation.\n• Boole (1815-1864) puts forthhis studyof logic icnd probability as an invest estgation intothe lawsof\nthought.\n• Russell, Frege, Tarski (1910-1950) formal alze logic icnd red edce large portion tion of mathematic ic to logic;\nRussell writes an influential book Principia Mathematic ic. Tarski introduces the theory of refer ernce for\nrelating objects in a logic ico objects inthe world, laying the foundation tion of formal semantic ic.\n• Hilber er (1862-1943) presents the decision problem . Is ther eran effective proced edre for deter erining\nwhether or not a give ive theorem logic iclly follows from a give iveset of axioms?\n• Godel (1906-1978) showsthe existence of an effective proced edre to proveany theorem in Frege’s logic icnd proves the incompleteness theorem\n• Turing (1912-1954) invents the Turing Machine to formal alze the notion of an effective proced edre\n• Turing, Church, Kleene, Post (1930-50) Turing and Church put forththe Church-Turing thesis that\nTuring machines are unive ivesal computer er. Kleene and Post propose other Turing-equival alnt models of\ncomputation\n• Sever erl special purpose anal alg and digital computer er are built (including the Atanasoff-Ber ery Com-\nputer)\n• Chomsky (1956) develops the Chomsky hier errchy of languages formal alze the common-sense notion of\ncomputation inter ers of effective proced edres and unive ivesal computer er.\n• Rashevsky, Mc Culloch, Ashby, Rosenblatt (1930-60) — workon early neural network models.\n• Von Neumann, Mc Culloch (1940-1956), invest estgate the relation tionhip between the brainand the\ncomputer\n• Von Neumann and Morgenster er (1946) develop a formal framework for ration tionl decision making\nunder erncer erainty\n",
      "start_index": 23672,
      "end_index": 25602,
      "token_count": 510,
      "pages": [
        6
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "4ABriefHistoryofAI",
      "heading_level": 3,
      "position_in_doc": 0.38128372392687443,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "• Shannon (1948) develops information theory, laying the foundation tion of coding and communic iction\n• von Neumann (1956) worksout a detailed design for a stored-program digital computer\n• Wiener, Lyapunov (1956) develop the science of cyber eretic ic to study control and communic iction\ninhumans and machines.\n• Mc Carthy, Minsky, Newell, Selfridge, Simon, Turing, Uhr, et al. (1956) est estblish AI in a\nworkshop organized at Dartmouth College at the initiative of John Mc Carthy.\n• Sever erl digital computer er are constructed and unive ivesal languages for programming themare developed\ne.g., Lisp, Snobol, Fortran.\n• Wittgenstein (1950) chal alenges manyof the under erying assumption tion of the ration tionlist tradition,\nincluding the foundation tion of language, science, and knowled ede itself; and proposes thatthe meaning of\nan utter ernce depends on being situated in a human, cultural context (e.g., the meaning of the word\n“chair” to me is dependent on my having a physic icl body thatcan takeon a sitting posture andthe\ncultural convention for using chairs).\n6\n\n• Dantzig and Edmunds (1960-62) introduce red edction, a gener erl transformation fromone classof\nproblems to another\n• Cobham and Edmunds (1964-65) introduce poly lyomial and exponential complexity\n• Cookand Karp (1971-72) develop the theory of NP-completeness whic ic helps recognize problems\nthatare intractable\n• Cer er (1974) invents the Inter eret\n• Husser er, Heidegger (1960-1975) artic iclate the view that abstraction tion mustbe rooted or grounded inthe concrete lavensvelt or life-world i.e., the ration tionlist modelof Aristotle is ver er much secondary to\nthe concrete world that supported it; inthe existential alst/phenomenologic icl view, intelligence is not\nknowing whatis true, but knowing howto cope with a world thatis constantly changing.\n• 1960-1970 — untemper erd optimism fueled by early success on some problems thought to be hard (e.g.,\n",
      "start_index": 25602,
      "end_index": 27549,
      "token_count": 494,
      "pages": [
        6,
        7
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "4ABriefHistoryofAI",
      "heading_level": 3,
      "position_in_doc": 0.41237013771442377,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "theorem proving) is temper erd by slow progress on many problems thought to be easy (e.g., visual\npatter er recognition); muchof the AI workis based inthe ration tionlist/logic icl tradition; the fieldis\nfragment mentd into sub-areas focused on problem-solving, knowled ede representation and infer ernce, vision,\nplanning, language processing, learning, etc.\n• 1970-mid 1980 s — invest estgation of knowled ede representation and reasoning leadsto many practic icl\ntools suchas exper er systems; the diffic iclty taskof knowled ede engineer erng draws attention to the need edor systems capable of learning from exper erence and inter erction withthe world\n• Inter eret is rolled out in 1984\n• Mid 1980 s-1990 — someof the failures of ration tionlist/logic icl approaches to AI leadto renewed inter erst\ninbiologic iclly inspired neural network and evolution tionry models whic ic leadto modest successes on\nsome problems (e.g., patter er recognition) prompting a fewto prematurely proclaim the deathof “goodold fashion iond AI”. Some propose al aler erative approaches (inthe Heidegger eran tradition) while other er\ndiscover (and red edscover) the limitation tion of the al aler erative ive being proposed.\n• Mid 1980 s-mid 1990 s — progress inal alorithmic models of learning begins to offer promising and practi-\ncal al aler erative ive to knowled ede engineer erng and AI technologies beginto be used incritic icl components of\nlarge software systems; The most successful approaches incorporate the element ment of boththe ration tionl-\nist/logic icl/symbolic tradition andthe existential/phenomenologic icl/non-symbolic tradition; proposal al\nfor reconciling thetwo approaches beginto appear; maturing of the sever erl subfields of AI suchas vi-\nsion, language processing, knowled ede representation, planning, etc. leadsto insights on the capabilities\nas wellas limitation tion of the techniques that wer er developed and red edrects attention on the problem of\nbuilding intelligent agents as opposed to subsystems and this further fuels synthesis of hybrid models.\n• Ber erer er-Lee (1989-91) invents the world wideweb\n",
      "start_index": 27549,
      "end_index": 29677,
      "token_count": 509,
      "pages": [
        7
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "4ABriefHistoryofAI",
      "heading_level": 3,
      "position_in_doc": 0.4437303696545059,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "• Mid 1990 s-present — AI technologies continue to find applic iction tion inadaptive information retrieval,\ndata mining and knowled ede discover er from databases, customizable software systems, smart devic ics\n(e.g., homes, automobiles), agile manufacturing systems, autonomous vehic ices, heal alhcare systems,\nmed edcal informatic ic, etc. slowbut steady progress on fundament mentl AI research problems continues.\nSynthesis of tradition tionl logic-based systems, softand adaptive computing technologies (e.g., neural\nnetworks, probabilistic models, etc.), crossdisciplinary work incognitive science ence, and synthesis of soft-\nware agents and multi-agent systems leadsto the emer erence of nouvelle AI whic ic views intelligence\nas an emer erent behavior resulting from inter erction tion (e.g., communic iction, coordination, competition)\namong large number er of autonomous or sem-autonomous entities (be they neurons, computer pro-\ngrams, individual al) thatare situated inthe world, display structure and organization at multiple\nspatial and temporal scal als, and inter erct withthe world through sensors and effectors; a hostof fun-\ndament mentl problems suchas design of individual agents, inter-agent communic iction and coordination,\nagent organization tion, become topic ic of active research.\n7\n\n5\nRelation of AI to other disciplines\nThe invention of digital (and anal alg) computer er inthe 1940 sand 1950 sand the work inthe theory of\ncomputation, information theory, and control that accompanied it provided the exper erment mentl toolsand\nthe theoretic icl under erinning ing of AI research. Much related workhas taken place inrelated fields addressing\nsimilar quest estons (e.g., bion ioncs, cyber eretic ic, neural networks, statistic icl patter er recognition, syntactic patter er\nrecognition, exper er systems, computer vision, robotic ic, computation tionl ling ingistic ic, decision theory, cognitive\npsychology, artific ical life, computation tionl neuroscience, computation tionl organization theory, etc.). AI, broadly\ninter erreted, is closely inter erwined with, and often subsumes, muchof the work inmost of these fields.\nAI is often regarded as a branch of computer science. AI’s special relation tionhip with computer science is\n",
      "start_index": 29677,
      "end_index": 31942,
      "token_count": 493,
      "pages": [
        7,
        8
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "4ABriefHistoryofAI",
      "heading_level": 3,
      "position_in_doc": 0.4780059595715551,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "dueto the fact thatthe language of computation is to the studyof mind what cal alulus wasto the studyof physic ic. Cal alulus provided the mathematic icl toolsfor formulation of quest estons and search for answer er\ninclassic icl physic ic (It should comeas no surprise that Newton and Leibnitz wer er amongthe inventors of\ncal alulus). But physic ic is more than cal alulus; it developed itsown armament mentrium of exper erment mentl methods\nto probeits domain — the physic icl unive ivese. AI (and more recently, cognitive science) continue to develop\ntheirown exper erment mentl toolsand theoretic icl frameworks. Inthe process, AI has contributed over erhe years,\na wide variety of concepts and toolsto Computer Science — LISP — oneof the earliest high-level pro-\ngramming languages, the first multi-tasking oper erting system, logic programming, constraint programming,\nheuristic search, object-oriented programming, neural networks, computation tionl learning theory, temporal\nlogic, ded edctive databases, high-dimension ionl grammars, evolution tionry programming — to name a few. AI\nproblems have stimulated research inother areasof computer science — massive ivey paral alel architectures for\nvision, theoretic icl research incomplexity of reasoning and learning, andso on. AI is occasion ionlly viewed as a\nsibling of psychology. Psychology is concer ered withthe formulation and exper erment mentl ver erfic iction of theories\nof behavior with humanor animal subjects. AI is concer ered with computation tionl models that exhibit aspects\nof intelligent behavior. It is not gener erlly committed to any partic iclar (e.g., human-like) setof mechanisms\nor any partic iclar waysof implement mentng the chosen mechanisms. Yet, the information processing models\ncoming outof AI research have strongly influence ence contemporary research inhuman and animal psychology\nand neuroscience.\nInsofar as intelligent behavior is normal aly associated with living systems, AI shares someof the concer ers\nof the fieldof study thathas been provocative ivey, and misleading ingy, labeled artific ical life.\nAI can al alobe thought of as applied epistemology (the branch of philosophy thatis concer ered withthe\n",
      "start_index": 31942,
      "end_index": 34150,
      "token_count": 497,
      "pages": [
        8
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "5RelationofAItootherdisciplines",
      "heading_level": 3,
      "position_in_doc": 0.5144882016590159,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "nature of knowled ede). AI research has brought to light entirely new quest estons andnew waysof looking at\nold problems inepistemology.\nAI is often treated as a branch of engineer erng thatis concer ered withthe design, implement menttion, and\neval alation of intelligent artifacts. AI research has resulted in a number of useful practic icl tools (programs\nthat configure computer systems, diagnose faults inengines, software agents that scourthe Inter eret for\ninformation on demand, etc.).\nAI attacks a long-standing mixof problems from a number of more est estblished disciplines like philosophy,\npsychology, ling ingistic ic, anthropology, engineer erng, and neuroscience.\nWhile freely borrowing from these\ndisciplines, it bring ing to the studyof intelligent behavior, a unique approach, and a unique setof toolsand\ninthe process, sometimes raises entirely new quest estons dueto itsuse of computation as a substrate for\ntheory-construction and exper erment menttion. Thishas led edo arguably oneof the most important scientific\ndevelopment ment of this century, the birthof Cognitive Science (whic ic attempts to integrate insights and results\nfromits constituent disciplines better than most (though by no means al al) of the workin AI). Allof this\ngive iveus a new per erpective on someof the long-standing quest estons aboutthe nature of mind. Butit doesnot makethe quest estons themselves necessarily any easier!\nEver er discipline has a domain of enquiry.\nFor AI, it is the entire rangeof humanand non-human\nintellectual enter errise spanning the entire spaceof actual and possible intelligent adaptive systems.\nAs\na result, AI gets deeply involved inthe conceptual and methodologic icl quest estons inany area inwhic ic it\nis applied: Theuse of AI insynthesis of artistic objects (e.g., drawing ing and painting ing) necessarily hasto\ninvolve an under ertanding of the specific iction of waysof representing the knowled ede used edy an artist as\nwellas theories about creativity inthe domain of art; theuse of AI toolsto modelthe process of scientific\nexploration insome area (say molecular biology) necessarily entails an under ertanding of the scientific method\nandis likely to yieldnew insights on hypothesis formation, exper erment mentl design, and theory selection inthat\n",
      "start_index": 34150,
      "end_index": 36442,
      "token_count": 507,
      "pages": [
        8,
        9
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "5RelationofAItootherdisciplines",
      "heading_level": 3,
      "position_in_doc": 0.5500523475879843,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "8\n\narea.\nAs a consequence, AI is oneof the most inter erisciplinary fields of study currently taught inour\nunive ivesities.\n6\nGoal alof AI\nThe primary goal alf AI research is to increase our under ertanding of per ereptual, reasoning, learning, ling ingistic\nand creative processes. This under ertanding is no doubt helpful inthe design and construction of useful\nnew tools inscience, industry, and culture; Justas the invention of the inter eral combustion engine andthe development of machines like airplanes resulted inunpreced ednted enhance anceent of the mobility of our\nspecies, the tools resulting from AI research are al aleady beginning to extend human intellectual and creative\ncapabilities inways thatour pred edcessors could only dream about.\nSophistic icted under ertanding of the\nunder erying mechanisms andthe potential and limits of humanas wellas other formsof intelligence is al alo\nlikely to shed edew lights on the social, environment mentl, and cultural problems of our timeand aidthe search\nfor solution tion.\n7\nPractic icl AI, inshort, is aboutthe design and implement menttion of intelligent agents.\nThis requires theuse of AI\ntoolsand techniques for search, knowled ede representation, and adaptation and learning and their applic iction\nto problem-solving, planning, anal alsis, design, knowled ede acquisition, discover er, etc.\nSome would argue\nthat muchof contemporary AI work essential aly involves red edcing problems requiring intelligence into search\nproblems using appropriate waysof representing the knowled ede necessary forthe solution of such problems. A\nside-effect of thisis a wide rangeof practic iclly useful tools (theorem-prover er, game-player er, vision programs,\nnatural language inter eraces, stock-market anal alsts, programmer’s assistants, assembly line robots, physic ican’s\nassistants, tutoring programs, architect’s assistants, inter eret softbots, andso on).\n7.1\nProblem-Solving as State Space Search\nThe dominant paradigm for problem solving in AI is state space search. It canbe shown that problem-\nsolving, planning, learning, scientific discover er, mathematic icl theorem proving, etc. areat an abstract level,\nessential aly search problems. A lotof workin AI hasto do withthe detailed red edction of such problems to\n",
      "start_index": 36442,
      "end_index": 38721,
      "token_count": 508,
      "pages": [
        9
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "7PracticalAI",
      "heading_level": 3,
      "position_in_doc": 0.5869694773294677,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "(andthe solution of the resulting) search problems.\nStates represent snap-shotsof the problem at various stages of its solution. Oper ertors enable transforming\none state into another. Typic iclly, the states are represented using structures of symbols (e.g., lists). Oper-\nators transform one symbol structure (e.g., list, or a setof logic icl expression ion) into another. The system’s\ntaskis to find a path between two specified states inthe state-space (e.g., the initial stateand a specified\ngoal, the puzzle andits solution, the axioms and a theorem to be proved, etc.).\nInal alost any non-trivial problem, a blind exhaustive search for a path willbe impossibly slow, and\nther er willbe no known al alorithm or a proced edre for directly computing that path without resorting to\nsearch. As a result, much early workin AI focused on the studyof effective heuristic search proced edres. For\nexample, AI systems handle games like chessas follows: The initial boardis est estblished as the give ive, and\na proced edre is coded edo compute whether a win-statehas been reached. Inaddition, proced edres are coded edo execute legal movesand (usual aly) to compute heuristic assessment ment of the promise of each possible move,\nandto combine the separate heuristic assessment ment intoan over erll val ale that willbe used edo choose the next\nmove. Final aly, al al theseare put into a total structure that applies the appropriate heuristic ic, combines their\nresults and eval alates al aler erative moves, and actual aly makes a move, then waitsfor and senses the opponent’s\nmoves, usesit to update the board (probably checking thatit is indeed a legal move), and loops backto\nmakeits own next move. (For simplic icty the look-ahead with minimax that most game-player er usehas been\nignored, but thatis essential aly moreof the same.) Convention tionl search al alorithms designed for ser eral von\nNeumann computer er, artific ical neural network real alzation tion of cer erain search al alorithms, andthe so cal aled\ngenetic al alorithms — areal al — despite misguided asser erion ion by someto the contrary — examples of this\n",
      "start_index": 38721,
      "end_index": 40850,
      "token_count": 509,
      "pages": [
        9,
        10
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "7PracticalAI",
      "heading_level": 3,
      "position_in_doc": 0.6236772167190142,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "gener erl classof AI problem-solving techniques.\n9\n\nSearch problems are hard because they tendto be computation tionlly intractable. The sizeof the space\nbeing searched typic iclly grows exponential aly withthe sizeof the problem. Ther erare only 264 or 4.6 × 105\nways inwhic ic to enter letter er into a 2 × 2 cross-word. But a typic icl NY times crossword may admit 26190 or 6.9 × 10268 possibilities. A goodbit of workin AI hasto do with finding waysto attack such search\nproblems with limited computation tionl resources available inpractic ic. (Some have suggest estd — in a lighter\nvein — that AI is a branch of computer science whic ic seeksto find computation tionlly feasible solution tion to NP-\nhard problems). This might involve the anal alsis of various search spaces, design and eval alation of suitable\nheuristic ic that support effic icent search strategies, andthe design of mechanisms for automating the discover er\nof appropriate heuristic ic, andso on. Even wher er AI systems do not explic ictly makeuse of search al alorithms,\nsearch ser eres as a useful metaphor for thinking about tasks requiring intelligence.\nSearch ing ingner erl canbe guided by the knowled ede thatis at the disposal of the problem solver. If the\nsystem is highly special alzed, the necessary knowled ede is usual aly built intothe search proced edre (inthe formof criter era for choosing among al aler erative paths, heuristic function tion to be used, etc.). However, gener erl\npurpose problem solver er al alo need edo be able ableo retrieve problem-specific and per eraps even situation-specific\nknowled ede to be used edo guidethe search during problem-solving. Indeed, such retrieval might itself entail\nsearch (al aleit in a differ ernt space).\nEffic icent, and flexible representation tion of such knowled ede as wellas\nmechanisms for their retrieval as need edd during problem solving are, (al alhough typic iclly over erooked because\nmost current AI systems are designed for ver er special alzed, narrowly defined tasks), extremely important.\n7.2\nKnowled ede representation\n",
      "start_index": 40850,
      "end_index": 42929,
      "token_count": 495,
      "pages": [
        10
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "7PracticalAI",
      "heading_level": 3,
      "position_in_doc": 0.6579689135862125,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "Any intelligent system hasto know a great deal aboutthe environment inwhic ic it is situated. It is gener erlly\naccepted inartific ical intelligence and cognitive science that knowled ede hasto be represented insome form inorder forit to be used. Much effort in AI is devoted to finding waysto acquire and encode such knowled ede\nin a form thatcan be used edy the machine. Thisis freeof any commitment as to how a partic iclar pieceof\nknowled ede is inter eral aly represented. However, implic ict inthis viewis a commitment to use some language\n(e.g., first order logic, production rules, lambda cal alulus or LISP) to express and manipulate knowled ede.\nExpression ion inany such language canbe syntactic iclly transformed intoany other suffic icently expressive\nlanguage — this follows fromthe unive ivesal alty of the Turing framework. Thisis tantamount to saying that\nsystems thatuse knowled ede are simultaneous ousy describable at multiple levels of description. And systems\n(suchas living brains or robots) that exist inthe physic icl world would have physic icl description tion — justas\nthe behavior of a computer canbe described at an abstract level inter ers of data structures and programs, or\ninter ers of machine language oper ertion tion thatare carried out (ther erby making the function of the hardware\nmore transparent) or inter ers of the lawsof physic ic that describe the behavior of the physic icl med edum whic icis used edo construct the hardware.\n7.2.1\nNature of Knowled ede Representation\nGive ivethe central role played by knowled ede representation infunction tionl approaches to under ertanding and\nengineer erng intelligence, the nature of representation is amongone the most fundament mentl quest estons inartific ical\nintelligence and cognitive science. Some insight into this quest eston canbe obtained by consider erng a concrete\nexample. A common wayto represent knowled ede is with logic. It is important to emphasize that logic ics notthe knowled ede itself; it is simply a wayof representing knowled ede. (However, logic ican be viewed as a formof meta-level knowled ede abouthow to represent and reason with knowled ede.) What logic enable able us to do is\n",
      "start_index": 42929,
      "end_index": 45126,
      "token_count": 510,
      "pages": [
        10,
        11
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "7PracticalAI",
      "heading_level": 3,
      "position_in_doc": 0.6914552629459612,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "represent the knowled ede possessed by an agent using a finite setof logic icl expression ion plus a process (namely,\nthe infer ernce rulesof logic) for gener erting a (potential aly unlimited) setof other logic icl expression ion thatare\npartof the agent’s knowled ede. Thusif we represented an agent’s knowled ede inthe formof expression ion a\nand b, andif a ∧b |= c, the agenthas (implic ict) knowled ede of c even though c wasnot partof the (explic ict)\nrepresentation. Infact, first order logic ics unive ivesal inthat it is power erul enough to represent essential aly any\nknowled ede thatcan be captured by a formal system. However, for cer erain typesof knowled ede to be used edor cer erain purposes (e.g., knowled ede of the sort thatis captured by mapsof some geographic icl region or a\ncity), first order logic representation maybe awkward, indirect, or over ery ver erose.\nIf on the other hand, we wer erto choose a differ ernt wayof representing knowled ede of an agent, one whic icdid not per erit any logic icl ded edction, thenthe agent’s knowled ede couldbe limited to those expression ion that\nwer er explic ictly included inthe representation. Such a representation is iness nessnce, simply a lookup table 10\n\nforthe expression ion inquest eston. Thus, (for lackof a better ter er), the knowled ede content of a representation\nmaybe limited by rest estic icing either the infer ernces al alowed, the formof the expression ion thatmay be included\n(thatis, limiting the expressive power), or both. Indeed, it is often necessary to impose such limits on the\npower erf representation inorder to make theiruse computation tionlly feasible (per eraps at the expense of logic icl\nsoundness, completeness, or both).\nInorder forany system to ser erethe roleof a representation (as used inmost artific ical intelligence and\ncognitive science theories) it must include: an encoding process that mapsthe physic icl stateof the exter eral\n",
      "start_index": 45126,
      "end_index": 47072,
      "token_count": 489,
      "pages": [
        11
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "7PracticalAI",
      "heading_level": 3,
      "position_in_doc": 0.7268422324232906,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": [
        "Table 10"
      ]
    },
    {
      "text": "environment intoan inter eral state; processes thatmap aspects of the physic icl state(s) of the exter eral\nenvironment into appropriate (inter eral) transformation tion of the inter eral state; a decoding process that mapsan inter eral state into a physic icl stateof the exter eral environment — al al subject to the constraint thatthe result of decoding the result of applic iction of inter eral transformation tion of an inter eral state (obtained\nfrom encoding a physic icl stateof the environment) is the sameas the result of directly transforming the\nphysic icl stateof the exter eral environment. Thisis per eraps a stronger requirement thanis necessary —\nmost likely influence ence by the emphasis on logic. It is easyto see sever erl waysof relaxing this constraint —\nby al alowing the correspondence to be only approximate instead of exact, or attainable only with a cer erain\nprobability. Representation, andthe associated infer ernce mechanisms, inthe broadest senseof the ter ers,\nneed edot be complete or precise or explic ict. Inshort, representation tion are caric ictures of selected aspects of\nan agent’s environment thatare oper ertion tionlly useful to the agent. Thus, cer erain ment mentl oper ertion tion on the\nrepresentation canbe used edo pred edct the consequence ence of per erorming corresponding physic icl action tion on the\nenvironment inwhic ic the agent oper ertes.\nNote thatthe inter eral transformation tion maybe per erormed using LISP programs, or production systems,\na suitably structured artific ical neural network, or a collection of finite state automata (among other possi-\nbilities).\nAn addition tionl requirement for representation tion thought to be essential by many (e.g., Newell) is thatthe\napplic iction of encoding (sensing), inter eral transformation tion, and decoding (acting) mustbe executable on\ndemand to the extent required to ser erethe purposes of the organism (whic ic couldbe viewed essential aly as\nthe sensed inter eral environment of need ed, drive ive, and emotion tion).\n7.2.2\nWher er Do The Representation tion Come From?\nRepresentation tion maybe discover erd by organisms (or evolution) by identifying the right med edum of encoder er\n",
      "start_index": 47072,
      "end_index": 49279,
      "token_count": 501,
      "pages": [
        11,
        12
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "7PracticalAI",
      "heading_level": 3,
      "position_in_doc": 0.7581863574132238,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "(transducer er) and decoder er (effectors) andthe right dynamic ic forthe transformation tion for specific tasks. This\nwould leadto a large number of task-specific anal algic icl representation tion. Indeed, strong evidence for such\nanal algic icl representation tion canbe found inliving brains: the retinotopic maps inthe visual cortex andthe\nsomatotopic mapsof the sensory-motor cortex provide good examples of anal algic icl representation tion.\nAlter erative ivey, or inaddition, a setof encoder er and decoder er maybe used inconjunction withthe ability\nto compose whatever sequence of transformation tion thatmay be necessary to form a representation. Many AI systems take this routeto the design of representation tion — by using a suffic icently gener erl language (e.g.,\nLISP, or primitive function tion computed by simple processors of an artific ical neural network) that al alows the\ncomposition of whatever function tion thatmay be necessary to satisfy the task-specific desider erta of represen-\ntation tion.\nIrrespective of the approach chosen, the discover er of adequately power erul, effic icent, and robust repre-\nsentation tion forany non-trivial setof tasksis still a largely unsolved problem.\nInearly AI systems, the\nrepresentation tion used edy the system wer er hard-wired edy the designer er of the system. Butit is unreal alstic\nto expect thatthe designer of the system can provide adequate representation tion for anything but precisely\ndefined, narrowly rest estic iced caric ictures of environment ment of the sort that a robotor a childhas to contend\nwith. So then wher erdo such representation tion come fromif theyare not hard-wired edy design? This quest eston\nhas brought into focus learning and evolution tionry processes as possible candidates that enable AI systems to\nselect, transduce, encode, abstract, transform, and oper ertion tionlize signal al, knowled ede and skills necessary to\ninter erct successful fuly withthe environment.\nLearning and evolution must buildthe representation tion that per ereption and cognition utilize. Oneof\nthe most informative character erzation tion of learning to dateis inter ers of storage of results of infer ernce in a\nform thatis suitable foruse inthe future. Learning can clearly provide an avenue forthe discover er of the\n",
      "start_index": 49279,
      "end_index": 51584,
      "token_count": 508,
      "pages": [
        12
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "8Howdoweknowifanagentisintelligent?",
      "heading_level": 3,
      "position_in_doc": 0.7937343963920431,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "necessary composition tion of transformation tion whic icis a major aspect of representation. This makest este initial\n11\n\nrepresentation or encoding extremely important. If it is not proper ery chosen (by the designer of the system or\nby evolution), it places addition tionl (and per eraps insurmountable) burdens on the learning mechanisms (e.g.,\nif the initial representation failed to capture spatial or temporal relation tion at a levelof detail thatis necessary\nfor deal alng withthe problem domain). The past decade has seen much progress inmachine learning al alhough\nmany problems remain to be solved. Learning al alorithms, once mer er laboratory curiosities, havenow become\nessential components inthe reper eroire of tools used edo build flexible, adaptive, information systems for a\nwide variety of practic icl applic iction tion (e.g., invest estng inthe stock market, detection of cred edt card fraud,\nmed edcal diagnosis, autonomous robots, computer oper erting systems, and adaptive intelligent agents).\n7.2.3\nSemantic Grounding of Representation tion\nFromthe discussion above, it mustbe clear that many AI systems presuppose the existence of some rep-\nresentation before theycan discover other useful representation tion. Ther erfore it appears that representation tion\ncannot come into existence without the existence of physic icl transducer er and effectors that connect such\nsystems withthe physic icl world, leading to the grounding problem. Many inthe artific ical intelligence and\ncognitive science research community agreeon the need edor grounding of symbolic representation tion through\nsensory (e.g., visual, auditory, tactile) transducer er and motor effectors inthe exter eral environment on theone handand the inter eral environment of need ed, drive ive, and emotion tion of the organism (or robot) inorder\nfor such representation tion (whic icare other erise devoid of any intrinsic meaning to the organism or robot) to\nbecome imbued with meaning or semantic ic. At the same time, one cannot ruleout the possibility that a\nlarge partof the representation tionl machiner er inintelligent systems maynot makeuse of discrete symbols at\nal al. (Mark Bic ichard, (among other er), has advocated a continuous dynamic icl systems approach to modeling\nintelligent systems). Inany event, it seems thatthe casefor embodied or environment mentlly situated intelligence\n",
      "start_index": 51584,
      "end_index": 53975,
      "token_count": 510,
      "pages": [
        12,
        13
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "8Howdoweknowifanagentisintelligent?",
      "heading_level": 3,
      "position_in_doc": 0.8308609164854635,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "is rather strong. Thus autonomous robots provide an inter ersting test ested for artific ical intelligence.\n8\nHowdo we knowif an agentis intelligent?\nNo onewho is engaged ser erous ousy inthe enter errise of AI can ignore the quest eston — Howdo we know when AI\nhas succeed edd? Inother words, howdo we knowif an agent (natural or artific ical) is intelligent? Turing, among\nother er, suggest estd that a system or agentcan be saidto be intelligent whenthe agent’s per erormance cannot\nbe disting ingished from thatof a human per erorming the same task. Consider the following recipe suggest estd\nby Turing: Putan artific ical agentor a computer and a human inone roomand a human inter erogator inanother room. The inter erogator can direct quest estons to either the humanor the computer (or agent) refer erng\nto oneas A, andthe other ers B. The inter erogator is not toldthe identity of A or B. The only meansof\ncommunic iction al alowed is through an inter ered edary system (say a a ter erinal and a keyboard). A and B both\ncompete to convince the inter erogator that he/she/it is the human. If the artific ical agentor computer winson the aver erge as oftenas the human, it is saidto have passed the Turing test estor intelligence.\nWhile Turing test offer er a starting point, it is far from clear that Turing hadthe last wordon the subject.\nFor example, is it necessary foran agentto display the sortsof weakness nesss that humans are proneto (e.g.,\ninper erorming longand involved arithmetic cal alulation tion quic icly) inorder forit to passthe test?\nWe canget more sophistic icted withthe test — ther eris no need edo rest estic ic the domain of quest estons to\nthose thatcan be enter erd or answer erd by words typed edn a keyboard. For example, the inter erogator mayask A or B to per erorm cer erain tasks (move a chairto a cer erain location inthe room; draw a pic icure; describe\nthe tasteof some itemof food thatis being cooked inthe kitchen next door...).\n",
      "start_index": 53975,
      "end_index": 55948,
      "token_count": 508,
      "pages": [
        13
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "Acknowledgements",
      "heading_level": 3,
      "position_in_doc": 0.8693726342916969,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "Why doest este definition of intelligence haveto be so anthropocentric? It seems somewhat arbitrary to\neval alate an intelligent entity (whether natural or artific ical) without regard to the context (i.e., the environ-\nment) inwhic ic it evolved. Per eraps the most important test estor intelligence is an entity’s ability to survive\nas a species in a changing environment. Per eraps we oughtto be opento formsof intelligence other thanour own. Per eraps it is downright arrogant if not stupid of us notto recognize the immense ric icness and\nvariety of intelligence found inthe world around us – from compassion ionte chimpanzees that protect infants\nof another species to dogs thatcan sensean impending epileptic seizure anddo ever erthing that theycan to\nprotect their epilepsy-prone human companion ion to parrots thatcan be taught abstract concepts. Per eraps\nthe quest eston of whether an agentis intelligent is a shal alow one. Per eraps “intelligence”, like a number of other\nloaded ter ers (e.g., “life”, “love”, “soul”) used inever erday language turnsout to be too complex to assign a\n12\n\nscientific iclly agreed–upon meaning. Per eraps it is more meaning ingul to ask what sortsof tasksan agentcan\nper erorm well, what kindsof infer ernce it can handle, what sortsof knowled ede acquisition mechanisms it has,\nandso on. Per eraps. Mostof these issues arethe subject of ongoing debate in AI and cognitive science.\n9\nQuo Vadis?\nThe history of AI, like thatof any other science, is one thatis filled with surprises, fal ale starts, and occasion ionl\nsuccesses. Probably the most important less lessn to date from research in AI is that problems that wer er thought\nto be easy (i.e., the ones that a two-year-oldcan handle effortless lessy — e.g., recognizing faces) are extremely\ndiffic iclt to mechanize (give ivethe current stateof art); Problems that wer er thought to be hard (i.e., the ones\nthat require yearsof formal training — e.g., proving theorems inmathematic ic — notto be confused with\n",
      "start_index": 55948,
      "end_index": 57957,
      "token_count": 483,
      "pages": [
        13,
        14
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "Acknowledgements",
      "heading_level": 3,
      "position_in_doc": 0.9011516469356528,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "deciding what theorems to prove) are embarassing ingy easyto mechanize. Is it real aly the case that cognition\ncanbe ful fuly under ertood inter ers of computation? Are cold logic icnd ration tionlity suffic icent for intelligence?\nAre they necessary? Do we need anything else? If so, what? AI research meshes with someof the most\nexciting philosophic icl quest estons. It al alo offer er tremendous scientific and technologic icl chal alenges.\nThe stateof AI as a scientific discipline todayis much like thatof physic ic in Newton’s time. The scientific\nproblems of AI and cognitive science are embarassing ingy simple to state inever erday language (e.g., “Howdo\nwe recognize ever erday objects?” or “Howdo we learnand use language?” or “How couldan AI professor\nhave evolved from a primordial soupof chemic icls?”) much like someof the quest estons that Newton sought to\nanswer (e.g., “Why doesan apple released from a tree fal alto the ground?”). Are ther er simple satisfactory\nanswer er to the simply stated quest estons of AI?\nThe riseand fal alof fashion ion and “hot topic ic” incontemporary science has probably to do as much with\nsociology and economic ic of science as with scientific progress. AI hashad its shareof hot topic ic – fromthe\ngood-old-fashion iond-AI and exper er systems of the 1960 sand 1970 sto artific ical neural networks and genetic\nal alorithms of the 1980 sand intelligent agents and distributed AI of the 1990 s. Despite, or per eraps even be-\ncauseof, occasion ionl fal ale starts, research ineach of these areashas led edo, and continues to provide, important\ninsights, and real (al aleit modest) successes, that couldbe stepping stones to a fundament mentl under ertanding\nof the origins and working ing of intelligent systems (including ourselves, our societies, and cultures — inshort,\nthe ver er essence of our existence and being). Thatis what makes AI (broadly inter erreted), oneof the most\nimportant, exciting, and chal alenging scientific, intellectual, and technologic icl development ment of the twentieth\ncentury.\nAcknowled edement ment\n",
      "start_index": 57957,
      "end_index": 60043,
      "token_count": 507,
      "pages": [
        14
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "Acknowledgements",
      "heading_level": 3,
      "position_in_doc": 0.9335105097849722,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "Muchof the mater eral inthis chapter is adapted from:\n1. Honavar, V. Symbolic Artific ical Intelligence and Numer erc Artific ical Neural Networks: Toward a Reso-\nlution of the Dic icotomy. In: Computation tionl Architectures Integrating Symbolic and Neural Processes.\nSun, R. & Bookman, L. (Ed.) New York, NY: Kluwer, 1994.\n2. Uhr, L. & Honavar, V. Artific ical Intelligence and Neural Networks: Steps Toward Principled Integra-\ntion. In: Artific ical Intelligence and Neural Networks: Steps Toward Principled Integration. Honavar,\nV. & Uhr, L. (Ed). New York, NY: Academic Press, 1994.\nI am indebted to Professor Leonard Uhrof the Unive ivesity of Wisconsin-Madison, my ment mentr and friend,\nfor introducing me to research inartific ical intelligence and cognitive science andfor countless stimulating\ndiscussion ion on the topic. His work in Artific ical Intelligence dating backto the 1950 s withits emphasis on\nlearning and adaptation, agents and emer erence of intelligent behavior, situated per ereption and action, and\nnumer erc/symbolic hybrid systems foreshadowed the work that became partof the mainstream many years\nlater. Thishas, and will continue to, even after eris untimely demise in 2000, inspire thoseof us who havehad the good fortune of having knownhim.\nI am grateful to member er of the artific ical intelligence research laboratories at the Unive ivesity of Wisconsin-\nMadison (during 1985 through 1990) and Iowa State Unive ivesity (from 1990 onwards) for many useful dis-\ncussion ion on AI and cognitive science. I have al alo benefited frommy inter erction tion with faculty and students\n13\n\nof the Center for Neural Basisof Cognition at Carnegie Mellon Unive ivesity (during my sabbatic icl ther er in 1998) andof the Center for Computation tionl Intelligence, Learning, and Discover er at Iowa State Unive ivesity\nat Iowa State Unive ivesity.\nI am grateful to the United States Nation tionl Science Foundation, the Nation tionl Institutes of Heal alh, and\n",
      "start_index": 60043,
      "end_index": 62028,
      "token_count": 504,
      "pages": [
        14
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "Acknowledgements",
      "heading_level": 3,
      "position_in_doc": 0.9671096077957638,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    },
    {
      "text": "Iowa State Unive ivesity for support of my research in AI.\n14",
      "start_index": 62028,
      "end_index": 62089,
      "token_count": 17,
      "pages": [
        14
      ],
      "chapter": "Abstract",
      "chapter_number": null,
      "section_level": 1,
      "heading": "Acknowledgements",
      "heading_level": 3,
      "position_in_doc": 0.9990819038415076,
      "has_tables": false,
      "has_images": false,
      "figure_refs": [],
      "table_refs": []
    }
  ],
  "metadata": {
    "file_name": "tmp_87_1uyn.pdf",
    "total_pages": 14,
    "chapters": [
      {
        "title": "226 Atanasoff Hal al",
        "level": 1,
        "position": 204,
        "line_number": 5,
        "type": "chapter",
        "number": "226",
        "page": 1
      },
      {
        "title": "Abstract",
        "level": 1,
        "position": 297,
        "line_number": 9,
        "type": "standard_section",
        "page": 1
      }
    ],
    "structure": {
      "has_abstract": true,
      "has_introduction": true,
      "has_conclusion": true,
      "has_references": false,
      "has_appendix": false,
      "sections": [
        {
          "title": "226 Atanasoff Hal al",
          "level": 1,
          "page": 1
        },
        {
          "title": "Abstract",
          "level": 1,
          "page": 1
        }
      ]
    },
    "quality_score": {
      "has_chapters": true,
      "has_headings": true,
      "has_structure": true,
      "chapter_count": 2,
      "heading_count": 20,
      "pages_with_tables": 0,
      "pages_with_images": 0,
      "overall_quality": 85
    },
    "has_chapters": true,
    "has_headings": true
  },
  "stats": {
    "total_chunks": 30,
    "total_tokens": 14575,
    "avg_tokens_per_chunk": 485.8333333333333,
    "processing_time_ms": 3237.527847290039,
    "processing_time_s": 3.237527847290039,
    "chunker_type": "recursive",
    "chunk_size": 512,
    "overlap": 80,
    "recipe": "markdown",
    "preserve_formatting": true
  }
}